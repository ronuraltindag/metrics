# Partialling out

```{css, echo=FALSE}
.badCode {
background-color: #ffffcf;
  color: black;
}
```

```{r , include=FALSE}

need <- c('glue', 'dplyr','readxl', 'haven', 'tidyr', 'tufte', 'formatR','knitr','rmdformats','ggplot2','broom')

have <- need %in% rownames(installed.packages()) 
if(any(!have)) install.packages(need[!have]) 
invisible(lapply(need, library, character.only=T)) 

knitr::opts_chunk$set(echo = TRUE)
rm(list=ls())
#change path to whereever you place the models
# script_folder = dirname(rstudioapi::getSourceEditorContext()$path)
# setwd(glue('{script_folder}'))

birthday<-"01011990" #january 1, 1990
set.seed(as.integer(birthday))
```

## Goals 

* Simulate a data-generating process (DGP) from scratch, given the population parameters 
* Show how to sample from the DGP to generate sample estimates
* Understand why these sample estimates can be different from the population values

* **Note** : Code chunks with STUDENTS are for intented to teach students, CHALLENGE are challenging but students with some programming skills can easily learn, PROF are for students with advanced programming skills and instructors.

## Overview

* We next make the DGP slightly more complicated -- with two independent variables -- and look at how our sample estimates are distributed across a series of sample draws from the population data.

## Generating data from a known linear multivariate DGP

* So let's perform a data generating process for a dependent variable $$y$$ which is given by the linear function $$y = \beta_0 + \beta_1 * x_1 + \beta_2 * x_2 +  u$$ where $\beta_0$ is the sum of the 1st and 2nd digit of my birthday, $\beta_1$ is the sum of the 3rd and 4th digit of my birthday, $\beta_2$ is 7, $x_1$ is distributed normal with mean of 10 and variance of the first non-zero digit of my birthday, $x_2$ is distributed normal with a mean of the last digit of my birthday, and variance of the sum of the first two digits, and u is (independently) distributed normal with mean 0 and variance of the last non-zero digit of your birthday. 

* Simulate "population" data of 1MM observations.

* So generate all the components, and then multiply and sum them to generate the column for Y, and combine all columns into a single dataframe.

```{r}
n <- 1000000
u<-rnorm(n, 0, sqrt(9))
x1<-rnorm(n, 10,sqrt(1))
x2<-rnorm(n, 0,sqrt(1))
beta0<-1
beta1<-1
beta2<-7
y<-beta0+beta1*x1+beta2*x2+u
df<-data.frame(y,x1,x2,u) 
head(df)
``` 

## Sampling from the population 

* Next, we will take a sample from the population data of 1,000 observation. 
```{r}
sample<- df[sample(nrow(df), 1000), ]
nrow(sample)
```

## Calculating sample estimates 

* And let's use the lm() command.
```{r}
model1<-lm(sample$y ~ sample$x1 + sample$x2)
summary(model1)

model1$coefficients
beta0_hat<-model1$coefficients[1]
beta1_hat<-model1$coefficients[2]
beta2_hat<-model1$coefficients[3]

```


* So our sample-derived regression function is given by: $$y = `r beta0_hat` + `r beta1_hat`*x1 + `r beta2_hat`*x2 + u$$


## Partialling out: extracting the unique information in $x_1$ 
```{r}
auxiliary<-lm(sample$x1 ~ sample$x2)
summary(auxiliary)
sample$residX1 <- residuals(auxiliary) 

model1PO<-lm(sample$y ~ sample$residX1)
summary(model1PO)
summary(model1)
```
  

