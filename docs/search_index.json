[
["index.html", "EC282 INTRODUCTION TO ECONOMETRICS Chapter 1 Course Logistics and using R 1.1 Goals 1.2 Course information 1.3 Requirements", " EC282 INTRODUCTION TO ECONOMETRICS Onur Altındağ Last update: 2020-01-05 Chapter 1 Course Logistics and using R 1.1 Goals Course introduction, syllabus, general logistics, etc. Install R and RStudio. Some pep talk on “how to cope with coding frustration”. Best practices relating to code/script development in the RStudio Integrated Development Environment (IDE). Areas of caution and some never-do’s. 1.2 Course information This is an introductory econometrics course that aims to provide you the basic set of tools to conduct data analysis and interpretation based on economic theory. The focus of the course is the theoretical and empirical foundations of statistical inference and modeling. We will study the basic mechanics of multivariate regression, problems related to its implementation and how to solve them. Towards the end of the semester, subject to a time constraint, we will also discuss issues related to in-sample and out-of-sample prediction problems. The course aims to be application oriented and you should develop, to the extend possible, some programming skills in R. At the end of the semester, I expect you to be familar with RStudio interface, basic data manipulation, obtaining and interpreting the sample statistics, conduct meaningful regression analysis and prediction. Importantly, we will not talk much about the elephant in the room: causal interpretation of any empirical analysis, which is left for the next metrics class that you will take. 1.3 Requirements Textbook: I will mainly use this web page and upload my hand to provide you some material and upload my hand-written lecture notes as well. There are two main textbooks that I heavily rely on to explain the theoretical framework: Studenmund’s Using Econometrics: A Practical Guide. Introductory Econometrics: A Modern Approach. Feel free to purchase an older edition or rent them. The "],
["intro.html", "Chapter 2 Introduction", " Chapter 2 Introduction Here is Onur speaking. I would like to add this. You can label chapter and section titles using {#label} after them, e.g., we can reference Chapter 2. If you do not manually label them, there will be automatic labels anyway, e.g., Chapter 4. Figures and tables with captions will be placed in figure and table environments, respectively. par(mar = c(4, 4, .1, .1)) plot(pressure, type = &#39;b&#39;, pch = 19) Figure 2.1: Here is a nice figure! Reference a figure by its code chunk label with the fig: prefix, e.g., see Figure 2.1. Similarly, you can reference tables generated from knitr::kable(), e.g., see Table 2.1. knitr::kable( head(iris, 20), caption = &#39;Here is a nice table!&#39;, booktabs = TRUE ) Table 2.1: Here is a nice table! Sepal.Length Sepal.Width Petal.Length Petal.Width Species 5.1 3.5 1.4 0.2 setosa 4.9 3.0 1.4 0.2 setosa 4.7 3.2 1.3 0.2 setosa 4.6 3.1 1.5 0.2 setosa 5.0 3.6 1.4 0.2 setosa 5.4 3.9 1.7 0.4 setosa 4.6 3.4 1.4 0.3 setosa 5.0 3.4 1.5 0.2 setosa 4.4 2.9 1.4 0.2 setosa 4.9 3.1 1.5 0.1 setosa 5.4 3.7 1.5 0.2 setosa 4.8 3.4 1.6 0.2 setosa 4.8 3.0 1.4 0.1 setosa 4.3 3.0 1.1 0.1 setosa 5.8 4.0 1.2 0.2 setosa 5.7 4.4 1.5 0.4 setosa 5.4 3.9 1.3 0.4 setosa 5.1 3.5 1.4 0.3 setosa 5.7 3.8 1.7 0.3 setosa 5.1 3.8 1.5 0.3 setosa You can write citations, too. For example, we are using the bookdown package (Xie 2019) in this sample book, which was built on top of R Markdown and knitr (Xie 2015). References "],
["prob-stat-review.html", "Chapter 3 Prob-Stat Review", " Chapter 3 Prob-Stat Review .badCode { background-color: #ffffcf; color: black; } 3.0.1 Goals Briefly review the concepts related to probability theory and statistics that we will frequently use in this class. Briefly review how to infer meaningful information about the population using random samples. 3.0.2 Flipping a coin Task: Define the mutually exclusive outcomes for flipping a coin and flip the coin one time. Answer: ## [1] &quot;heads&quot; 3.0.3 Probability Task: Show that if you repeat the exercise many times (e.g. 1000), the coin will come up heads roughly half of the time. That is P(head) = 0.5 Answer: ## event.outcome ## heads tail ## 495 505 DIFFICULT answer: lln &lt;- function (X){ outcome.set &lt;- c(&quot;heads&quot;,&quot;tail&quot;) event.outcome &lt;- replicate(X, sample(outcome.set, 1)) y1 &lt;- as.data.frame(event.outcome) %&gt;% mutate(trials=X) return(y1) } out1 &lt;- do.call(rbind.data.frame,lapply(seq(10,1000,10), lln)) %&gt;% group_by(trials, event.outcome) %&gt;% count() %&gt;% mutate(frac=n/trials) g1 &lt;- ggplot(data=out1, aes(x=trials,y=frac, colour=event.outcome)) + geom_segment(aes(x = trials,y = frac, xend = trials, yend = 1-frac), size = 0.3, colour=&#39;#969696&#39;) + geom_point(size=1.5) + geom_hline(yintercept = 0.5, colour=&#39;black&#39;, linetype=&#39;dashed&#39;, size=0.5) + ylim(0.25, 0.75) + theme_fivethirtyeight() + coord_flip() + scale_colour_manual(name=&#39;&#39;, values = c(&#39;#1FA67A&#39;,&#39;red&#39;)) + labs(x = &quot;number of coins flipped&quot;, y = &quot;fraction of heads and tails&quot;) + theme(legend.position=&quot;bottom&quot;) plot(g1) 3.0.4 Expected value and variance Task: Define a random variable X = {0,1} through assigning zero to heads and 1 to tails. Calculate the expected value, variance, and the standard deviation of the random variable X: \\(\\mu=E[X]=\\sum_iX_iP(X_i)\\) and \\(\\sigma^2=E[(X-\\mu)^2]=\\sum_i[(X_i-\\mu)^2 P(X_i)]\\) Answer: #define an empty matrix 2 by 6 df1 &lt;- matrix(NA, nrow = 2, ncol = 6) #transform this to a data set (easier to work with) df1 &lt;- as.data.frame(df1) #change the col names names(df1) &lt;- c(&quot;outcome&quot;, &quot;X&quot;, &quot;P(X)&quot;, &quot;X.P(X)&quot;, &quot;X-E[X]&quot;, &quot;(X-E[X])^2.P(X)&quot;) #define the outcomes df1$outcome &lt;- c(&quot;heads&quot;, &quot;tail&quot;) #define values assigned to each outcome df1$X &lt;- c(0,1) #define the associated probabilities df1$`P(X)` &lt;- c(0.5,0.5) #weight each outcome with the assigned probability df1$`X.P(X)` &lt;- df1$X * df1$`P(X)` #calculate the expexted value mu.x &lt;- sum(df1$`X.P(X)`) #calculate the dev. from mean for each outcome df1$`X-E[X]` &lt;- df1$X - mu.x #weight the squared dev. from mean by the assigned probability df1$`(X-E[X])^2.P(X)` &lt;- (df1$`X-E[X]`)^2 * df1$`P(X)` #calculate the variance var.x &lt;- sum(df1$`(X-E[X])^2.P(X)`) #std. dev sigma.x &lt;- sqrt(var.x) #show the filled data set df1 ## outcome X P(X) X.P(X) X-E[X] (X-E[X])^2.P(X) ## 1 heads 0 0.5 0.0 -0.5 0.125 ## 2 tail 1 0.5 0.5 0.5 0.125 #show the mean, variance, and standard deviation rbind(mu.x,var.x, sigma.x) ## [,1] ## mu.x 0.50 ## var.x 0.25 ## sigma.x 0.50 3.0.5 Law of Large Numbers Formally, the sample average, \\(\\bar{x}\\), will almost surely converge in probablity to \\(\\mu\\) as \\(N \\rightarrow \\infty\\). In practice, here is what it looks like. Task: Define the random variable X={0,1} as previously described. Flip the coin for an increasing number of times, n={1,2,3….,1000}, and calculate the average of each sample. Interpret the expected value. Answer: Law of Large Numbers (LLN) theorem predicts that if an experiment is repeated many times the average outcome should be very close to the expected value, observe how difference between the observed sample average and expected value approach each other as the number of coins that we experiment with increases. Expected value is therefore the long run average of a random variable. flips &lt;- function(n,p,x1,x2) { out1 &lt;- sample(x=c(x1,x2), prob = c(p,1-p), size=n, replace = TRUE) n.sample &lt;- n mean.sample &lt;- sum(out1)/n sd.sample &lt;- sqrt(sum((out1-mean.sample)^2)/n) out2 &lt;- cbind(mean.sample, n.sample, sd.sample) return(out2) } df1 &lt;- do.call(rbind.data.frame,lapply(1:1000, flips,p=0.5,x1=0,x2=1)) p1 &lt;- ggplot(df1, aes(x=n.sample,y=mean.sample)) + theme_tufte() + geom_line() + geom_hline(yintercept = 0.5, colour=&#39;grey&#39;, linetype=&#39;dashed&#39;) + labs(x = &quot;number of coins flipped&quot;, y = &quot;outcome mean&quot;) + transition_reveal(n.sample) + view_follow() + xlim(1,1000 ) + ylim(0.0,1.0) animate(p1, nframes=200, fps=5) 3.0.6 Central limit theorem CLT is a fundamental tool in data analysis, there are many versions with similar implications. We will demonstrate a simple one. Formally, assume that you have an identically and independently distributed random variable X. Notice that the shape of its outcome distibution does not matter. You draw a random sample of \\(N\\) observations through repeated experimentation such as \\(\\{X_1,X_2,..,X_n\\}\\). Assume that you are interested in the sample average \\(\\bar{X}=\\dfrac{X_1+X_2+...+X_n}{n}\\). CLT states that, no matter what the initial distribution of X is, the sample average of X can be approximated with a normal distribution with mean \\(\\mu\\) and standard deviation \\(\\dfrac{\\sigma}{\\sqrt{n}}\\) for sufficiently large \\(n\\). Here is how it works. Task: Flip 10 coins using random variable X={0,1} as defined before and calculate the sample average \\(\\bar{X}\\). Answer: #define your sample size=10 n &lt;- 10 #define the number times that you want to repeat the experiment r=1000 r &lt;- 1000 #define the possible outcomes X={0,1} x1 &lt;- 0 x2 &lt;- 1 #define the probabilities for each outcome p1 &lt;- 0.5 p2 &lt;- 0.5 #now run the experiment exp.outcome &lt;- sample(x=c(x1,x2), prob=c(p1,p2), size=10, replace=TRUE) exp.outcome ## [1] 1 0 0 1 0 1 0 1 0 0 mean(exp.outcome) ## [1] 0.4 Task: Repeat the 10-coin experiment many times (e.g. ~ 10,000) and calculate the average of outcomes for each experiment. Graph a frequency histogram of these averages, that is the distribution of \\(\\bar{X}\\). HARD answer: #write a small function f.coins &lt;- function(n) { sample.n &lt;- sample(x=c(0,1), prob=c(0.5,0.5), size=n, replace=TRUE) mean.sample &lt;- mean(sample.n) return(mean.sample) } #now try if it is working f.coins(10) ## [1] 0.6 #replicate 10000 times df1 &lt;- replicate(10000, f.coins(10)) #see if the data looks right head(df1) ## [1] 0.4 0.4 0.4 0.6 0.4 0.8 #now plot hist.df1 &lt;- hist(df1, xlab=&#39;sample average of 10-coins&#39;, ylab=&#39;frequency (over 10000)&#39;,main=&#39;&#39;) Task: Gradually increase your sample size from 10 to 100 and plot the frequency distribution of \\(\\bar{X}\\) with increasing \\(n\\). "],
["methods.html", "Chapter 4 Methods", " Chapter 4 Methods We describe our methods in this chapter. "],
["applications.html", "Chapter 5 Applications 5.1 Example one 5.2 Example two", " Chapter 5 Applications Some significant applications are demonstrated in this chapter. 5.1 Example one 5.2 Example two "],
["final-words.html", "Chapter 6 Final Words", " Chapter 6 Final Words We have finished a nice book. "],
["references.html", "References", " References "]
]
