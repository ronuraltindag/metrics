# Prob-Stat Review

```{css, echo=FALSE}
.badCode {
background-color: #ffffcf;
  color: black;
}
```

```{r include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
devtools::install_github("ropenscilabs/icon")

need <- c('glue', 'dplyr','readxl', 'haven', 'ggplot2','tidyr','zoo','ggrepel','gganimate',
          'ggimage', 'ggthemes','tufte', 'formatR', 'magick', 'devtools','icon')

have <- need %in% rownames(installed.packages()) 
if(any(!have)) install.packages(need[!have]) 
invisible(lapply(need, library, character.only=T)) 

```

### Goals 

* Briefly review the concepts related to probability theory and statistics that we will frequently use in this class. 
* Briefly review how to infer meaningful information about the population using random samples. 


### Flipping a coin

**Task**: Define the mutually exclusive outcomes for flipping a coin and flip the coin one time.  



 Answer:

```{r ch1, echo=FALSE, message=F, warning=F, class.source='badCode', results='markup', tidy=TRUE}
#define the set of possible outcomes for the event 
outcome.set <- c("heads","tail")
#randomly pick one of the equally likely outcomes
sample(outcome.set,1)
```

### Probability
**Task**: Show that if you repeat the exercise many times (e.g. 1000), the coin will come up heads roughly half of the time. That is **P(head) = 0.5** 



Answer:
```{r ch2, echo=FALSE, message=F, warning=F, class.source="badCode", results='markup', tidy=FALSE}
#define the set of possible outcomes
outcome.set <- c("heads","tail")
#flip the coin 1000 times and save it into a list
event.outcome <- replicate(1000, sample(outcome.set, 1))
#calculate the number of heads
table(event.outcome)
```

DIFFICULT answer:
```{r ch3, fig.asp=1.3, fig.width=5, message=FALSE, warning=FALSE, class.source="badCode", results='markup', tidy=FALSE}
lln <- function (X){
  outcome.set <- c("heads","tail")
  event.outcome <- replicate(X, sample(outcome.set, 1))
  y1 <- as.data.frame(event.outcome) %>%
    mutate(trials=X)
  return(y1)
}

out1 <- do.call(rbind.data.frame,lapply(seq(10,1000,10), lln)) %>%
  group_by(trials, event.outcome) %>%
  count() %>%
  mutate(frac=n/trials)


g1 <- ggplot(data=out1, aes(x=trials,y=frac, colour=event.outcome)) + 
geom_segment(aes(x = trials,y = frac, xend = trials, yend = 1-frac), size = 0.3, colour='#969696') +  
geom_point(size=1.5) + 
geom_hline(yintercept = 0.5, colour='black', linetype='dashed', size=0.5) + 
ylim(0.25, 0.75) + 
theme_fivethirtyeight() + 
coord_flip() +  
scale_colour_manual(name='', values = c('#1FA67A','red'))  + 
labs(x = "number of coins flipped", y = "fraction of heads and tails")  + 
  theme(legend.position="bottom")



plot(g1)
  
```

### Expected value and variance
**Task**: Define a random variable X = {0,1} through assigning zero to heads and 1 to tails. Calculate the expected value, variance, and the standard deviation of the random variable X:  $\mu=E[X]=\sum_iX_iP(X_i)$ and  $\sigma^2=E[(X-\mu)^2]=\sum_i[(X_i-\mu)^2 P(X_i)]$ 

Answer:


```{r ch4, message=FALSE, warning=FALSE, class.source="badCode", results='markup', tidy=FALSE}
#define an empty matrix 2 by 6 
df1 <- matrix(NA, nrow = 2, ncol = 6)
#transform this to a data set (easier to work with) 
df1 <- as.data.frame(df1)
#change the col names 
names(df1) <- c("outcome", "X", "P(X)", "X.P(X)", "X-E[X]", "(X-E[X])^2.P(X)") 
#define the outcomes
df1$outcome <- c("heads", "tail") 
#define values assigned to each outcome
df1$X <- c(0,1) 
#define the associated probabilities 
df1$`P(X)` <- c(0.5,0.5) 
#weight each outcome with the assigned probability 
df1$`X.P(X)` <- df1$X * df1$`P(X)`
#calculate the expexted value 
mu.x <- sum(df1$`X.P(X)`)
#calculate the dev. from mean for each outcome 
df1$`X-E[X]` <- df1$X - mu.x 
#weight the squared dev. from mean by the assigned probability 
df1$`(X-E[X])^2.P(X)` <- (df1$`X-E[X]`)^2 * df1$`P(X)`
#calculate the variance 
var.x <- sum(df1$`(X-E[X])^2.P(X)`)
#std. dev 
sigma.x <- sqrt(var.x)
#show the filled data set
df1 
#show the mean, variance, and standard deviation 
rbind(mu.x,var.x, sigma.x)  
```

### Law of Large Numbers 

Formally, the sample average, $\bar{x}$,  will **almost surely** converge in **probablity** to $\mu$ as $N \rightarrow \infty$. In practice, here is what it looks like.  

**Task:** Define the random variable X={0,1} as previously described. Flip the coin for an increasing number of times, n={1,2,3....,1000}, and calculate the average of each sample. Interpret the expected value. 

Answer: Law of Large Numbers (LLN) theorem predicts that if an experiment is repeated many times the average outcome should be very close to the expected value, observe how difference between the observed sample average and expected value approach each other as the number of coins that we experiment with increases. Expected value is therefore the long run average of a random variable.

```{r ch5, message=FALSE, warning=FALSE, class.source="badCode", results=FALSE, tidy=FALSE, echo=TRUE}

flips <- function(n,p,x1,x2) {
  out1 <- sample(x=c(x1,x2), prob = c(p,1-p), size=n, replace = TRUE)
  n.sample <- n 
  mean.sample <- sum(out1)/n 
  sd.sample <- sqrt(sum((out1-mean.sample)^2)/n)
  out2 <- cbind(mean.sample, n.sample, sd.sample)
  return(out2)
}

df1 <- do.call(rbind.data.frame,lapply(1:1000, flips,p=0.5,x1=0,x2=1)) 

p1 <- ggplot(df1, aes(x=n.sample,y=mean.sample)) +
      theme_tufte() +
      geom_line() + 
      geom_hline(yintercept = 0.5, colour='grey', linetype='dashed') +
      labs(x = "number of coins flipped", y = "outcome mean") + 
      transition_reveal(n.sample) + 
      view_follow() + 
      xlim(1,1000 ) + 
      ylim(0.0,1.0) 



animate(p1, nframes=200, fps=5)

```

### Central limit theorem 

CLT is a fundamental tool in data analysis, there are many versions with similar implications. We will demonstrate a simple one. Formally, assume that you have an **identically and independently** distributed  random variable X. Notice that the shape of its outcome distibution does not matter. 

You draw a random sample of $N$ observations through repeated experimentation such as $\{X_1,X_2,..,X_n\}$. Assume that you are interested in the sample average $\bar{X}=\dfrac{X_1+X_2+...+X_n}{n}$. CLT states that, **no matter what the initial distribution of X is**, the sample average of X can be approximated with a **normal distribution** with mean $\mu$ and standard deviation $\dfrac{\sigma}{\sqrt{n}}$ for sufficiently large $n$. Here is how it works. 

    

**Task:** Flip 10 coins using random variable **X={0,1}** as defined before and calculate the sample average $\bar{X}$. 

 Answer:
 
```{r, results='markup', tidy=FALSE, class.source="badCode",message=F, warning=F}
#define your sample size=10 
n <- 10 
#define the number times that you want to repeat the experiment r=1000
r <- 1000 
#define the possible outcomes X={0,1}
x1 <- 0 
x2 <- 1 
#define the probabilities for each outcome 
p1 <- 0.5 
p2 <- 0.5 
#now run the experiment 
exp.outcome <- sample(x=c(x1,x2), prob=c(p1,p2), size=10, replace=TRUE) 
exp.outcome
mean(exp.outcome)


````

**Task:** Repeat the 10-coin experiment many times (e.g. ~ 10,000) and calculate the average of outcomes for each experiment. Graph a frequency **histogram** of these averages, that is the distribution of $\bar{X}$.  

HARD answer:

```{r, results='markup', tidy=FALSE, class.source="badCode",message=F, warning=F}
#write a small function 
f.coins <- function(n) {
sample.n <- sample(x=c(0,1), prob=c(0.5,0.5), size=n, replace=TRUE)
mean.sample <- mean(sample.n)
return(mean.sample)
}

#now try if it is working 
f.coins(10)
#replicate 10000 times 
df1 <- replicate(10000, f.coins(10))
#see if the data looks right 
head(df1)
#now plot 
hist.df1 <- hist(df1,  xlab='sample average of 10-coins', ylab='frequency (over 10000)',main='')
````

**Task:** Gradually increase your sample size from 10 to 100 and plot the **frequency** distribution of $\bar{X}$ with increasing $n$.    

<!-- DIFFICULT answer: -->

<!-- ```{r ch6, message=FALSE, warning=FALSE, class.source="badCode", results='markup', tidy=FALSE} -->
<!-- #write a small function  -->
<!-- f.coins <- function(n1) { -->
<!-- sample.n1 <- mean(sample(x=c(0,1), prob=c(0.5,0.5), size=n1, replace=TRUE)) -->
<!-- return(sample.n1) -->
<!-- } -->

<!-- f.coins2 <- function(n2) { -->
<!--   sample.n2 <- replicate(10000, f.coins(n2)) -->
<!--   out1 <- cbind(sample.n2, rep(n2,n2)) -->
<!-- } -->

<!-- df1 <- do.call(rbind.data.frame,lapply(seq(10,100,1), f.coins2))  -->
<!-- names(df1) <- c('xbar','n1') -->


<!-- p1 <- ggplot(df1, aes(xbar)) + -->
<!--       theme_tufte() + -->
<!--       geom_histogram(binwidth=0.01, colour="black", fill="white") +  -->
<!--       labs(title = "Number of coins (n): {current_frame}",  -->
<!--             x = "sample average", y = "frequency") +  -->
<!--       transition_manual(n1) -->
<!--       #shadow_trail() -->
<!--       #xlim(1,1000 ) +  -->
<!--       #ylim(0.0,1.0)  -->

<!-- animate(p1, nframes=200, fps=10) -->

<!-- ``` -->

<!-- **Task:** Plot the **density** distribution of the sample averages.     -->
<!-- DIFFICULT answer: -->

<!-- ```{r ch7, message=FALSE, warning=FALSE, class.source="badCode", results='markup', tidy=FALSE} -->


<!-- p1 <- ggplot(df1, aes(xbar)) + -->
<!--       theme_tufte() + -->
<!--       geom_histogram(aes(y=..ndensity..), colour="black", fill="white", binwidth=0.01) +  -->
<!--       geom_density(aes(y=..ndensity..), alpha=.2, fill="#FF6666", colour='red') + -->
<!--       theme(axis.text.y = element_blank(), axis.ticks.y = element_blank()) +  -->
<!--       labs(title = "Number of coins: {current_frame}",  -->
<!--            x = "sample average", y = "density") +  -->
<!--       transition_manual(n1) -->

<!-- animate(p1, nframes=200, fps=5) -->

<!-- ``` -->

<!-- ### Standard normal distribution  -->



<!-- **Task:** Standardize the outcomes from 100-coin experiment above (average of the 100-coins for X={0,1}) and plot the **density** distribution of the standardized random variable $Z=\dfrac{X-\mu}{\sigma/\sqrt{N}}$. Interpret Z={-2,0,2}.  -->

<!-- DIFFICULT answer: -->

<!-- ```{r ch8, message=FALSE, warning=FALSE, class.source="badCode", results='markup', tidy=FALSE} -->
<!-- #write a small function  -->
<!-- f.coins <- function(n1) { -->
<!-- sample.n1 <- mean(sample(x=c(0,1), prob=c(0.5,0.5), size=n1, replace=TRUE)) -->
<!-- sample.n1z <- (sample.n1-0.5)/(0.5/sqrt(n1)) -->
<!-- return(sample.n1z) -->
<!-- } -->

<!-- f.coins2 <- function(n2) { -->
<!--   sample.n2 <- replicate(10000, f.coins(n2)) -->
<!--   out1 <- cbind(sample.n2, rep(n2,n2)) -->
<!-- } -->

<!-- df1 <- do.call(rbind.data.frame,lapply(seq(10,1000,10), f.coins2))  -->

<!-- p1 <- ggplot(df1, aes(sample.n2)) + -->
<!--       theme_tufte() + -->
<!--       geom_histogram(aes(y=..density..), colour="black", fill="white", bw=0.01) +  -->
<!--       #geom_density(alpha=.2, fill="#FF6666", colour='red') + -->
<!--       stat_function(fun=dnorm, aes(x=rnorm(length(df1$sample.n2))), colour='red') +  -->
<!--       labs(title = "Number of coins: {current_frame}",  -->
<!--            x = "standardized outcome (z-score)", y = "density") +  -->
<!--       transition_manual(V2) -->

<!-- animate(p1, nframes=200, fps=5) -->

<!-- ``` -->







